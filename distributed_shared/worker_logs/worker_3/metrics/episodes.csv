episode,global_step,timestamp,elapsed_time,episode_steps,episode_reward,episode_length,episode_collection_time,avg_step_time,total_episodes,worker_id,reward_change,avg_reward_last_100,distributed_training,sync_due,loss_total,loss_policy,loss_value,loss_entropy,reward_mean,reward_std,training_time,action_selection_mean,action_selection_std,action_selection_total,env_step_mean,env_step_std,env_step_total,episode_collection_mean,episode_collection_std,episode_collection_total,training_mean,training_std,training_total,global_step_mean,global_step_std,global_step_min,global_step_max,global_step_final,episode_mean,episode_std,episode_min,episode_max,episode_final,step_mean,step_std,step_min,step_max,step_final,timestamp_mean,timestamp_std,timestamp_min,timestamp_max,timestamp_final,elapsed_time_mean,elapsed_time_std,elapsed_time_min,elapsed_time_max,elapsed_time_final,worker_id_mean,worker_id_std,worker_id_min,worker_id_max,worker_id_final,action_space_size_mean,action_space_size_std,action_space_size_min,action_space_size_max,action_space_size_final,gpu_memory_gb_mean,gpu_memory_gb_std,gpu_memory_gb_min,gpu_memory_gb_max,gpu_memory_gb_final,gpu_memory_max_gb_mean,gpu_memory_max_gb_std,gpu_memory_max_gb_min,gpu_memory_max_gb_max,gpu_memory_max_gb_final,step_reward_mean,step_reward_std,step_reward_min,step_reward_max,step_reward_final,step_action_mean,step_action_std,step_action_min,step_action_max,step_action_final,step_log_prob_mean,step_log_prob_std,step_log_prob_min,step_log_prob_max,step_log_prob_final,step_obs_mean_mean,step_obs_mean_std,step_obs_mean_min,step_obs_mean_max,step_obs_mean_final,step_obs_std_mean,step_obs_std_std,step_obs_std_min,step_obs_std_max,step_obs_std_final,step_obs_max_mean,step_obs_max_std,step_obs_max_min,step_obs_max_max,step_obs_max_final,step_obs_min_mean,step_obs_min_std,step_obs_min_min,step_obs_min_max,step_obs_min_final,action_selection_time_mean,action_selection_time_std,action_selection_time_min,action_selection_time_max,action_selection_time_final,env_step_time_mean,env_step_time_std,env_step_time_min,env_step_time_max,env_step_time_final,cumulative_reward_mean,cumulative_reward_std,cumulative_reward_min,cumulative_reward_max,cumulative_reward_final
0,11,1752712457.2655518,3.806788682937622,11,10.0,10,0.7662391662597656,0.06783475875854492,1,3,0.0,10.0,True,False,18.785496251173317,-0.028836967162787986,19.49191198348999,-0.6775787651538849,1.0,0.0,0.4955332279205322,0.06711413860321044,0.19500556822001106,0.6711413860321045,0.0007206201553344727,0.00027808111719314533,0.0072062015533447266,0.7662391662597656,0.0,0.7662391662597656,0.4955332279205322,0.0,0.4955332279205322,5.0,3.1622776601683795,0,10,10,0.0,0.0,0,0,0,5.0,3.1622776601683795,0,10,10,1752712456.6153824,0.21078908552226164,1752712455.9535298,1752712456.728016,1752712456.728016,3.1566193103790283,0.21078899252346317,2.4947669506073,3.2692525386810303,3.2692525386810303,3.0,0.0,3,3,3,2.0,0.0,2,2,2,0.00772437182339755,0.00228343086461785,0.0005035400390625,0.008452892303466797,0.008452892303466797,0.00861258940263228,0.0025643095573281,0.0005035400390625,0.009429931640625,0.009429931640625,1.0,0.0,1.0,1.0,1.0,0.2,0.4000000000000001,0.0,1.0,0.0,-0.6555286526679993,0.09711477089163964,-0.8783302307128906,-0.5300403833389282,-0.5300403833389282,0.11566530764102936,0.06122231413238126,0.049041785299777985,0.24222254753112793,0.24222254753112793,0.9660204410552978,0.6573835508660394,0.2628111243247986,1.9977024793624878,1.9370843172073364,1.0957728922367096,0.6907241479341776,0.36971431970596313,2.246546983718872,1.9545694589614868,-0.9125855609774589,0.6530080049609789,-2.0046236515045166,-0.23288968205451965,-1.6528048515319824,0.06711413860321044,0.19500556822001106,0.001497507095336914,0.6521213054656982,0.005410909652709961,0.0007206201553344727,0.00027808111719314533,0.00023221969604492188,0.0011413097381591797,0.0011413097381591797,5.5,2.8722813232690143,1.0,10.0,10.0
