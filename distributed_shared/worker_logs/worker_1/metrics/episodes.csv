episode,global_step,timestamp,elapsed_time,episode_steps,episode_reward,episode_length,episode_collection_time,avg_step_time,total_episodes,worker_id,reward_change,avg_reward_last_100,distributed_training,sync_due,loss_total,loss_policy,loss_value,loss_entropy,reward_mean,reward_std,training_time,action_selection_mean,action_selection_std,action_selection_total,env_step_mean,env_step_std,env_step_total,episode_collection_mean,episode_collection_std,episode_collection_total,training_mean,training_std,training_total,global_step_mean,global_step_std,global_step_min,global_step_max,global_step_final,episode_mean,episode_std,episode_min,episode_max,episode_final,step_mean,step_std,step_min,step_max,step_final,timestamp_mean,timestamp_std,timestamp_min,timestamp_max,timestamp_final,elapsed_time_mean,elapsed_time_std,elapsed_time_min,elapsed_time_max,elapsed_time_final,worker_id_mean,worker_id_std,worker_id_min,worker_id_max,worker_id_final,action_space_size_mean,action_space_size_std,action_space_size_min,action_space_size_max,action_space_size_final,gpu_memory_gb_mean,gpu_memory_gb_std,gpu_memory_gb_min,gpu_memory_gb_max,gpu_memory_gb_final,gpu_memory_max_gb_mean,gpu_memory_max_gb_std,gpu_memory_max_gb_min,gpu_memory_max_gb_max,gpu_memory_max_gb_final,step_reward_mean,step_reward_std,step_reward_min,step_reward_max,step_reward_final,step_action_mean,step_action_std,step_action_min,step_action_max,step_action_final,step_log_prob_mean,step_log_prob_std,step_log_prob_min,step_log_prob_max,step_log_prob_final,step_obs_mean_mean,step_obs_mean_std,step_obs_mean_min,step_obs_mean_max,step_obs_mean_final,step_obs_std_mean,step_obs_std_std,step_obs_std_min,step_obs_std_max,step_obs_std_final,step_obs_max_mean,step_obs_max_std,step_obs_max_min,step_obs_max_max,step_obs_max_final,step_obs_min_mean,step_obs_min_std,step_obs_min_min,step_obs_min_max,step_obs_min_final,action_selection_time_mean,action_selection_time_std,action_selection_time_min,action_selection_time_max,action_selection_time_final,env_step_time_mean,env_step_time_std,env_step_time_min,env_step_time_max,env_step_time_final,cumulative_reward_mean,cumulative_reward_std,cumulative_reward_min,cumulative_reward_max,cumulative_reward_final
0,58,1752712459.2141156,5.476221799850464,58,57.0,57,1.2102570533752441,0.015255982415717944,1,1,0.0,57.0,True,False,151.34770242027008,-0.007788353646174073,152.04464721679688,-0.6891564428806305,1.0,0.0,0.29540300369262695,0.011842819682338782,0.06091811765920824,0.6750407218933105,0.0034131627333791634,0.0007745003330798096,0.1945502758026123,1.2102570533752441,0.0,1.2102570533752441,0.29540300369262695,0.0,0.29540300369262695,28.5,16.740669042783207,0,57,57,0.0,0.0,0,0,0,28.5,16.740669042783207,0,57,57,1752712458.4978845,0.24031848775679734,1752712457.6712766,1752712458.8849096,1752712458.8849096,4.759990934667917,0.24031844078008432,3.933382987976074,5.147015571594238,5.147015571594238,1.0,0.0,1,1,1,2.0,0.0,2,2,2,0.008342545607994342,0.0010385637456615734,0.0005035400390625,0.008520126342773438,0.008520126342773438,0.009302739439339474,0.0011657159312330324,0.0005035400390625,0.00949716567993164,0.00949716567993164,1.0,0.0,1.0,1.0,1.0,0.5263157894736842,0.49930699897395464,0.0,1.0,0.0,-0.6871928154376515,0.059839184458135936,-0.7823109030723572,-0.5991543531417847,-0.7231758832931519,0.10448341898358705,0.06152761356117821,-0.00282403826713562,0.18137913942337036,0.0562596321105957,0.6058830741727561,0.4462104429538278,0.0734761655330658,2.1634280681610107,2.1634280681610107,0.7598048779263831,0.4653877782244978,0.1021067276597023,2.331512212753296,2.331512212753296,-0.5126973612789523,0.42524962471072614,-1.9128111600875854,-0.06828099489212036,-1.9128111600875854,0.011842819682338782,0.06091811765920824,0.0023109912872314453,0.4676802158355713,0.004152774810791016,0.0034131627333791634,0.0007745003330798096,0.0020236968994140625,0.0053653717041015625,0.004158496856689453,29.0,16.451950239004088,1.0,57.0,57.0
