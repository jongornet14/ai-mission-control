episode,global_step,timestamp,elapsed_time,episode_steps,episode_reward,episode_length,episode_collection_time,avg_step_time,total_episodes,worker_id,reward_change,avg_reward_last_100,distributed_training,sync_due,loss_total,loss_policy,loss_value,loss_entropy,reward_mean,reward_std,training_time,action_selection_mean,action_selection_std,action_selection_total,env_step_mean,env_step_std,env_step_total,episode_collection_mean,episode_collection_std,episode_collection_total,training_mean,training_std,training_total,global_step_mean,global_step_std,global_step_min,global_step_max,global_step_final,episode_mean,episode_std,episode_min,episode_max,episode_final,step_mean,step_std,step_min,step_max,step_final,timestamp_mean,timestamp_std,timestamp_min,timestamp_max,timestamp_final,elapsed_time_mean,elapsed_time_std,elapsed_time_min,elapsed_time_max,elapsed_time_final,worker_id_mean,worker_id_std,worker_id_min,worker_id_max,worker_id_final,action_space_size_mean,action_space_size_std,action_space_size_min,action_space_size_max,action_space_size_final,gpu_memory_gb_mean,gpu_memory_gb_std,gpu_memory_gb_min,gpu_memory_gb_max,gpu_memory_gb_final,gpu_memory_max_gb_mean,gpu_memory_max_gb_std,gpu_memory_max_gb_min,gpu_memory_max_gb_max,gpu_memory_max_gb_final,step_reward_mean,step_reward_std,step_reward_min,step_reward_max,step_reward_final,step_action_mean,step_action_std,step_action_min,step_action_max,step_action_final,step_log_prob_mean,step_log_prob_std,step_log_prob_min,step_log_prob_max,step_log_prob_final,step_obs_mean_mean,step_obs_mean_std,step_obs_mean_min,step_obs_mean_max,step_obs_mean_final,step_obs_std_mean,step_obs_std_std,step_obs_std_min,step_obs_std_max,step_obs_std_final,step_obs_max_mean,step_obs_max_std,step_obs_max_min,step_obs_max_max,step_obs_max_final,step_obs_min_mean,step_obs_min_std,step_obs_min_min,step_obs_min_max,step_obs_min_final,action_selection_time_mean,action_selection_time_std,action_selection_time_min,action_selection_time_max,action_selection_time_final,env_step_time_mean,env_step_time_std,env_step_time_min,env_step_time_max,env_step_time_final,cumulative_reward_mean,cumulative_reward_std,cumulative_reward_min,cumulative_reward_max,cumulative_reward_final
0,46,1752712588.9767222,2.6821043491363525,46,45.0,45,0.8214104175567627,0.012890031602647569,1,6,0.0,45.0,True,False,125.36414095554501,-0.02888725008815527,126.07008743286133,-0.6770592272281647,1.0,0.0,0.38902831077575684,0.009951416651407878,0.04408535396189911,0.4478137493133545,0.002938614951239692,0.00029477643723387103,0.13223767280578613,0.8214104175567627,0.0,0.8214104175567627,0.38902831077575684,0.0,0.38902831077575684,22.5,13.275918047351754,0,45,45,0.0,0.0,0,0,0,22.5,13.275918047351754,0,45,45,1752712588.2938156,0.1677524489404955,1752712587.7284334,1752712588.552424,1752712588.552424,1.999196990676548,0.16775247255385045,1.4338154792785645,2.2578060626983643,2.2578060626983643,6.0,0.0,6,6,6,2.0,0.0,2,2,2,0.008298272671906845,0.0011621154184731873,0.0005035400390625,0.008502960205078125,0.008502960205078125,0.009254072023474651,0.0013045817061084844,0.0005035400390625,0.009479999542236328,0.009479999542236328,1.0,0.0,1.0,1.0,1.0,0.4888888888888889,0.4998765279645331,0.0,1.0,1.0,-0.6741934219996134,0.07635876163472824,-0.869295597076416,-0.5023422241210938,-0.776604950428009,-0.4993346626559893,0.4343719712183689,-1.5116900205612183,-0.061185285449028015,-1.5116900205612183,0.653518896136019,0.22651699617854604,0.07942170649766922,1.1122583150863647,0.791620135307312,0.20764972201238077,0.3264070626934439,-0.7697368264198303,0.8094649314880371,-0.5616593956947327,-1.2305711878670587,0.5969460661422415,-2.302358627319336,-0.13288235664367676,-2.302358627319336,0.009951416651407878,0.04408535396189911,0.002293825149536133,0.3023681640625,0.0032918453216552734,0.002938614951239692,0.00029477643723387103,0.002038717269897461,0.0035409927368164062,0.0030455589294433594,23.0,12.987173159185437,1.0,45.0,45.0
