episode,global_step,timestamp,elapsed_time,episode_steps,episode_reward,episode_length,episode_collection_time,avg_step_time,total_episodes,worker_id,reward_change,avg_reward_last_100,distributed_training,sync_due,loss_total,loss_policy,loss_value,loss_entropy,reward_mean,reward_std,training_time,action_selection_mean,action_selection_std,action_selection_total,env_step_mean,env_step_std,env_step_total,episode_collection_mean,episode_collection_std,episode_collection_total,training_mean,training_std,training_total,global_step_mean,global_step_std,global_step_min,global_step_max,global_step_final,episode_mean,episode_std,episode_min,episode_max,episode_final,step_mean,step_std,step_min,step_max,step_final,timestamp_mean,timestamp_std,timestamp_min,timestamp_max,timestamp_final,elapsed_time_mean,elapsed_time_std,elapsed_time_min,elapsed_time_max,elapsed_time_final,worker_id_mean,worker_id_std,worker_id_min,worker_id_max,worker_id_final,action_space_size_mean,action_space_size_std,action_space_size_min,action_space_size_max,action_space_size_final,gpu_memory_gb_mean,gpu_memory_gb_std,gpu_memory_gb_min,gpu_memory_gb_max,gpu_memory_gb_final,gpu_memory_max_gb_mean,gpu_memory_max_gb_std,gpu_memory_max_gb_min,gpu_memory_max_gb_max,gpu_memory_max_gb_final,step_reward_mean,step_reward_std,step_reward_min,step_reward_max,step_reward_final,step_action_mean,step_action_std,step_action_min,step_action_max,step_action_final,step_log_prob_mean,step_log_prob_std,step_log_prob_min,step_log_prob_max,step_log_prob_final,step_obs_mean_mean,step_obs_mean_std,step_obs_mean_min,step_obs_mean_max,step_obs_mean_final,step_obs_std_mean,step_obs_std_std,step_obs_std_min,step_obs_std_max,step_obs_std_final,step_obs_max_mean,step_obs_max_std,step_obs_max_min,step_obs_max_max,step_obs_max_final,step_obs_min_mean,step_obs_min_std,step_obs_min_min,step_obs_min_max,step_obs_min_final,action_selection_time_mean,action_selection_time_std,action_selection_time_min,action_selection_time_max,action_selection_time_final,env_step_time_mean,env_step_time_std,env_step_time_min,env_step_time_max,env_step_time_final,cumulative_reward_mean,cumulative_reward_std,cumulative_reward_min,cumulative_reward_max,cumulative_reward_final
0,14,1752712458.8479602,4.710582733154297,14,13.0,13,0.5996050834655762,0.03860075657184307,1,5,0.0,13.0,True,False,28.488329365018465,-0.05966080808295615,29.182571983337404,-0.6345818102359772,1.0,0.0,0.3068859577178955,0.034864333959726185,0.10733438679621363,0.45323634147644043,0.0037364226121168872,0.0005439471711911468,0.04857349395751953,0.5996050834655762,0.0,0.5996050834655762,0.3068859577178955,0.0,0.3068859577178955,6.5,4.031128874149275,0,13,13,0.0,0.0,0,0,0,6.5,4.031128874149275,0,13,13,1752712458.377875,0.14220105893562537,1752712457.9010153,1752712458.5075507,1752712458.5075507,4.240497742380414,0.1422009571823613,3.7636382579803467,4.370173454284668,4.370173454284668,5.0,0.0,5,5,5,2.0,0.0,2,2,2,0.00788109643118722,0.0020461724898029015,0.0005035400390625,0.008457183837890625,0.008457183837890625,0.008788347244262695,0.0022977978799560614,0.0005035400390625,0.009434223175048828,0.009434223175048828,1.0,0.0,1.0,1.0,1.0,0.3076923076923077,0.46153846153846156,0.0,1.0,1.0,-0.6940445899963379,0.16483148160945205,-0.9627553224563599,-0.511069655418396,-0.9503234624862671,-0.20514447070085085,0.04790136601121984,-0.24820362031459808,-0.10047626495361328,-0.10047626495361328,1.2447940042385688,0.6267374348737001,0.2897767126560211,2.3508107662200928,2.3508107662200928,1.1817222054188068,0.5913083556213309,0.06507343053817749,2.0775623321533203,2.0775623321533203,-1.3576255257313068,0.583939898078674,-2.2536861896514893,-0.5002985000610352,-2.2536861896514893,0.034864333959726185,0.10733438679621363,0.002305746078491211,0.40666699409484863,0.005366802215576172,0.0037364226121168872,0.0005439471711911468,0.0028684139251708984,0.004769086837768555,0.004046916961669922,7.0,3.7416573867739413,1.0,13.0,13.0
