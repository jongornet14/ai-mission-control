episode,global_step,timestamp,elapsed_time,episode_steps,episode_reward,episode_length,episode_collection_time,avg_step_time,total_episodes,worker_id,reward_change,avg_reward_last_100,distributed_training,sync_due,loss_total,loss_policy,loss_value,loss_entropy,reward_mean,reward_std,training_time,action_selection_mean,action_selection_std,action_selection_total,env_step_mean,env_step_std,env_step_total,episode_collection_mean,episode_collection_std,episode_collection_total,training_mean,training_std,training_total,global_step_mean,global_step_std,global_step_min,global_step_max,global_step_final,episode_mean,episode_std,episode_min,episode_max,episode_final,step_mean,step_std,step_min,step_max,step_final,timestamp_mean,timestamp_std,timestamp_min,timestamp_max,timestamp_final,elapsed_time_mean,elapsed_time_std,elapsed_time_min,elapsed_time_max,elapsed_time_final,worker_id_mean,worker_id_std,worker_id_min,worker_id_max,worker_id_final,action_space_size_mean,action_space_size_std,action_space_size_min,action_space_size_max,action_space_size_final,gpu_memory_gb_mean,gpu_memory_gb_std,gpu_memory_gb_min,gpu_memory_gb_max,gpu_memory_gb_final,gpu_memory_max_gb_mean,gpu_memory_max_gb_std,gpu_memory_max_gb_min,gpu_memory_max_gb_max,gpu_memory_max_gb_final,step_reward_mean,step_reward_std,step_reward_min,step_reward_max,step_reward_final,step_action_mean,step_action_std,step_action_min,step_action_max,step_action_final,step_log_prob_mean,step_log_prob_std,step_log_prob_min,step_log_prob_max,step_log_prob_final,step_obs_mean_mean,step_obs_mean_std,step_obs_mean_min,step_obs_mean_max,step_obs_mean_final,step_obs_std_mean,step_obs_std_std,step_obs_std_min,step_obs_std_max,step_obs_std_final,step_obs_max_mean,step_obs_max_std,step_obs_max_min,step_obs_max_max,step_obs_max_final,step_obs_min_mean,step_obs_min_std,step_obs_min_min,step_obs_min_max,step_obs_min_final,action_selection_time_mean,action_selection_time_std,action_selection_time_min,action_selection_time_max,action_selection_time_final,env_step_time_mean,env_step_time_std,env_step_time_min,env_step_time_max,env_step_time_final,cumulative_reward_mean,cumulative_reward_std,cumulative_reward_min,cumulative_reward_max,cumulative_reward_final
0,19,1752712458.9985867,4.960853099822998,19,18.0,18,0.586207389831543,0.025978313552008733,1,2,0.0,18.0,True,False,46.307448554494314,-0.03252555682427385,47.02402954101562,-0.6840554296970367,1.0,0.0,0.30569887161254883,0.02230170038011339,0.07458424119962971,0.401430606842041,0.003676613171895345,0.0006751570162513766,0.06617903709411621,0.586207389831543,0.0,0.586207389831543,0.30569887161254883,0.0,0.30569887161254883,9.0,5.477225575051661,0,18,18,0.0,0.0,0,0,0,9.0,5.477225575051661,0,18,18,1752712458.519692,0.12656732835109658,1752712458.067021,1752712458.6579437,1752712458.6579437,4.48195827634711,0.1265672337852294,4.029287815093994,4.620210409164429,4.620210409164429,2.0,0.0,2,2,2,2.0,0.0,2,2,2,0.008033827731483862,0.0017749205304790077,0.0005035400390625,0.008464336395263672,0.008464336395263672,0.008959443945633737,0.0019930887553105993,0.0005035400390625,0.009441375732421875,0.009441375732421875,1.0,0.0,1.0,1.0,1.0,0.5555555555555556,0.4969039949999533,0.0,1.0,0.0,-0.6881967319382561,0.06097247835579481,-0.8151834607124329,-0.5676906108856201,-0.6176775097846985,-0.18659076881077555,0.07033513790935665,-0.36540305614471436,-0.11444272845983505,-0.36540305614471436,0.7504076129860349,0.5635748344810774,0.3081851005554199,1.8746975660324097,1.7183773517608643,0.596126512520843,0.600851981217856,0.1116456538438797,1.9223921298980713,1.2130622863769531,-0.9846609400378333,0.58022748094809,-2.190525531768799,-0.5418399572372437,-2.0762856006622314,0.02230170038011339,0.07458424119962971,0.0036242008209228516,0.32981395721435547,0.003794431686401367,0.003676613171895345,0.0006751570162513766,0.002785205841064453,0.005194902420043945,0.0035681724548339844,9.5,5.188127472091127,1.0,18.0,18.0
