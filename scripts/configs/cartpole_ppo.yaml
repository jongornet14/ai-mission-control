# FILENAME: configs/cartpole_ppo.yaml
# CartPole-v1 with PPO configuration

experiment:
  name: "cartpole_ppo_experiment"
  save_dir: "./experiments"
  seed: 42

environment:
  name: "CartPole-v1"
  type: "gym"
  max_episode_steps: 500
  normalize_observations: true
  frame_skip: 1

algorithm:
  name: "PPO"
  learning_rate: 3e-4
  gamma: 0.99
  lambda: 0.95
  clip_epsilon: 0.2
  entropy_coef: 1e-4
  critic_coef: 1.0
  max_grad_norm: 1.0
  num_epochs: 10
  batch_size: 64
  num_cells: 256

training:
  total_frames: 100000
  frames_per_batch: 1000
  eval_frequency: 10
  eval_episodes: 5
  save_frequency: 50
  log_frequency: 1

hyperparameter_optimization:
  enabled: false
  method: "Random"
  t_ready: 5000
  bounds:
    learning_rate: [1e-5, 1e-2]
    clip_epsilon: [0.1, 0.5]
    lambda: [0.9, 1.0]
    batch_size: [32, 256]

logging:
  tensorboard: true
  wandb: false
  save_models: true
  log_level: "INFO"

---
# FILENAME: configs/pendulum_ppo.yaml
# Pendulum-v1 with PPO configuration

experiment:
  name: "pendulum_ppo_experiment"
  save_dir: "./experiments"
  seed: 42

environment:
  name: "Pendulum-v1"
  type: "gym"
  max_episode_steps: 200
  normalize_observations: true
  frame_skip: 1

algorithm:
  name: "PPO"
  learning_rate: 1e-3
  gamma: 0.99
  lambda: 0.95
  clip_epsilon: 0.2
  entropy_coef: 1e-3
  critic_coef: 1.0
  max_grad_norm: 1.0
  num_epochs: 10
  batch_size: 128
  num_cells: 256

training:
  total_frames: 500000
  frames_per_batch: 2048
  eval_frequency: 10
  eval_episodes: 10
  save_frequency: 25
  log_frequency: 1

hyperparameter_optimization:
  enabled: true
  method: "GP-UCB"
  t_ready: 50000
  bounds:
    learning_rate: [1e-5, 1e-2]
    clip_epsilon: [0.1, 0.5]
    lambda: [0.9, 1.0]
    batch_size: [64, 512]
    entropy_coef: [1e-5, 1e-2]

logging:
  tensorboard: true
  wandb: false
  save_models: true
  log_level: "INFO"

---
# FILENAME: configs/hyperopt_example.yaml
# Example with aggressive hyperparameter optimization

experiment:
  name: "hyperopt_aggressive_experiment"
  save_dir: "./experiments"
  seed: 123

environment:
  name: "CartPole-v1"
  type: "gym"
  max_episode_steps: 500
  normalize_observations: true
  frame_skip: 1

algorithm:
  name: "PPO"
  learning_rate: 3e-4  # Will be optimized
  gamma: 0.99
  lambda: 0.95  # Will be optimized
  clip_epsilon: 0.2  # Will be optimized
  entropy_coef: 1e-4
  critic_coef: 1.0
  max_grad_norm: 1.0
  num_epochs: 10
  batch_size: 64  # Will be optimized
  num_cells: 256

training:
  total_frames: 200000
  frames_per_batch: 1000
  eval_frequency: 5
  eval_episodes: 3
  save_frequency: 20
  log_frequency: 1

hyperparameter_optimization:
  enabled: true
  method: "HyperBand"  # or "GP-UCB", "Random", etc.
  t_ready: 5000  # Start optimizing after 5k frames
  bounds:
    learning_rate: [1e-5, 1e-2]
    clip_epsilon: [0.05, 0.8]
    lambda: [0.8, 1.0]
    batch_size: [16, 256]
    entropy_coef: [1e-6, 1e-2]

logging:
  tensorboard: true
  wandb: false
  save_models: true
  log_level: "INFO"

---
# FILENAME: configs/mujoco_example.yaml
# MuJoCo environment example (requires MuJoCo)

experiment:
  name: "mujoco_ppo_experiment"
  save_dir: "./experiments"
  seed: 42

environment:
  name: "HalfCheetah-v4"
  type: "gym"
  max_episode_steps: 1000
  normalize_observations: true
  frame_skip: 1

algorithm:
  name: "PPO"
  learning_rate: 3e-4
  gamma: 0.99
  lambda: 0.95
  clip_epsilon: 0.2
  entropy_coef: 0.0  # Often disabled for continuous control
  critic_coef: 1.0
  max_grad_norm: 0.5
  num_epochs: 10
  batch_size: 128
  num_cells: 512  # Larger networks for complex tasks

training:
  total_frames: 2000000  # Longer training for complex tasks
  frames_per_batch: 4096  # Larger batches
  eval_frequency: 25
  eval_episodes: 10
  save_frequency: 100
  log_frequency: 1

hyperparameter_optimization:
  enabled: false  # Start without hyperopt for complex environments
  method: "GP-UCB"
  t_ready: 100000
  bounds:
    learning_rate: [1e-5, 1e-3]
    clip_epsilon: [0.1, 0.3]
    lambda: [0.9, 1.0]

logging:
  tensorboard: true
  wandb: false
  save_models: true
  log_level: "INFO"