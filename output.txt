ğŸ¥ Running distributed worker health check...
[0;34m========================================[0m
[0;34m   Distributed Worker Health Check[0m
[0;34m========================================[0m

[0;35mğŸ“Š CONTAINER STATUS CHECK[0m
================================
[0;32mâœ… Found 4 active worker containers[0m

Worker Container Details:
NAMES                           STATUS                             CREATED          PORTS
ai-mission-control-worker-2-1   Up 46 seconds (health: starting)   46 seconds ago   6006/tcp, 8080/tcp, 8888/tcp
ai-mission-control-worker-0-1   Up 46 seconds (health: starting)   46 seconds ago   6006/tcp, 8080/tcp, 8888/tcp
ai-mission-control-worker-1-1   Up 46 seconds (health: starting)   46 seconds ago   6006/tcp, 8080/tcp, 8888/tcp
ai-mission-control-worker-3-1   Up 46 seconds (health: starting)   46 seconds ago   6006/tcp, 8080/tcp, 8888/tcp

[0;32mâœ… No workers in restart loop[0m


[0;35mğŸ” WORKER PROCESS CHECK[0m
================================

--- ai-mission-control-worker-2-1 ---
[0;32mâœ… Python training process active (PID: 1)[0m
[1;33mâš ï¸  Low/no CPU usage detected[0m
[0;32mâœ… Memory usage: 2.1%[0m

--- ai-mission-control-worker-0-1 ---
[0;32mâœ… Python training process active (PID: 1)[0m
[1;33mâš ï¸  Low/no CPU usage detected[0m
[0;32mâœ… Memory usage: 2.1%[0m

--- ai-mission-control-worker-1-1 ---
[0;32mâœ… Python training process active (PID: 1)[0m
[1;33mâš ï¸  Low/no CPU usage detected[0m
[0;32mâœ… Memory usage: 2.1%[0m

--- ai-mission-control-worker-3-1 ---
[0;32mâœ… Python training process active (PID: 1)[0m
[1;33mâš ï¸  Low/no CPU usage detected[0m
[0;32mâœ… Memory usage: 2.1%[0m


[0;35mğŸ–¥ï¸  GPU USAGE CHECK[0m
================================
[0;32mâœ… GPU accessible from workers[0m
index, name, memory.used [MiB], memory.total [MiB], utilization.gpu [%]
0, NVIDIA GeForce RTX 2070 SUPER, 1634 MiB, 8192 MiB, 94 %
[0;32mâœ… GPU memory in use: 1634MiB[0m


[0;35mğŸ“ LOG GENERATION CHECK[0m
================================
[0;32mâœ… distributed_shared directory exists[0m
[0;32mâœ… Found 6 worker log directories[0m
[0;32mâœ… TensorBoard logs found in 5 workers[0m
[1;33mâš ï¸  No recent log activity (last 5 minutes)[0m
[0;32mâœ… Found 15 model checkpoints[0m


[0;35mğŸ“ˆ TRAINING PROGRESS CHECK[0m
================================
[0;32mâœ… Recent coordinator activity:[0m
BEST WORKER: 0 (Score: 58.9154)
âœ… Copied best model from worker 0
âœ… Sync 2 completed successfully
[0;32mâœ… Found performance metrics for 2 workers[0m

Latest Worker Performance:
  Worker 0: 150 episodes, avg reward: 139.00
  Worker 99: 0 episodes, avg reward: 0.00


[0;35mğŸ”„ WORKER COMMUNICATION CHECK[0m
================================
[0;32mâœ… Found 3 coordination signals[0m
[1;33mâš ï¸  Best model is old (39 minutes old)[0m


[0;34mğŸ“Š HEALTH SUMMARY[0m
================================
[0;32mâœ… Container Status: HEALTHY[0m
[0;32mâœ… Log Generation: WORKING[0m
[0;32mâœ… Model Checkpoints: FOUND[0m
[0;32mâœ… Performance Metrics: AVAILABLE[0m

[0;34mOverall Health: 4/6 checks passed[0m
[0;32mâœ… Workers appear to be functioning correctly! ğŸ‰[0m

ğŸ’¡ Next steps:
  - Monitor progress: make distributed-logs
  - View TensorBoard: make distributed-tensorboard
  - Check GPU usage: make distributed-watch-gpu
